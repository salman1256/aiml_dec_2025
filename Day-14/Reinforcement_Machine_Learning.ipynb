{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Bf5kqCed6zSs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states=[0,1] #0 Dark ,1 Bright"
      ],
      "metadata": {
        "id": "zCz7nebN7aVX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actions=[0,1] # 0 Do nothing , 1 Turn On light"
      ],
      "metadata": {
        "id": "zS428BAs7j3c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('actions: ',actions)\n",
        "print('states: ',states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf_WFI2q7zYx",
        "outputId": "5070ffab-d565-468b-ba35-da57a7f4eaf2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actions:  [0, 1]\n",
            "states:  [0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q=np.zeros((len(states),len(actions)),dtype=np.int32)  # state*actions"
      ],
      "metadata": {
        "id": "948vu66g8tE0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u7gTXmIi9EBn",
        "outputId": "0b140f14-2343-48b8-bf35-be36cfaef401"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha=0.1 #Learning rate\n",
        "gamma=0.9 #Discount factor\n",
        "epsilon=0.2 #Exploration Rate\n",
        "episodes=100 # Training Runs"
      ],
      "metadata": {
        "id": "yT9ycC3B9nrT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Enviroment Functions\n",
        "def get_next_state(action):\n",
        "    if action==1:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "xwPgXn7q-MAC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reward Function\n",
        "def get_reward(state):\n",
        "  if state == 1:\n",
        "    return 10\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "_LxUCaDA-uZX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "for episode in range(episodes):\n",
        "  state=0  #dark room\n",
        "  action=random.choice(actions)\n",
        "  next_state=get_next_state(action)\n",
        "  reward=get_reward(next_state)\n",
        "\n",
        "  Q[state,action]=Q[state,action]+alpha*(reward+gamma*np.max(Q[next_state])-Q[state,action])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z4gY1IhnAIbN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Learned Q-Table')\n",
        "print(Q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj1OY0iKBT68",
        "outputId": "9d4fe744-2aa9-417f-9142-b14e6d457b8d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned Q-Table\n",
            "[[0 1]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state=int(input('Enter Room State : 0=Dark , 1=Bright: \\t'))\n",
        "for step in range(10):\n",
        "  action=actions[np.argmax(Q[state])]\n",
        "  print('Action: ',action)\n",
        "  state=get_next_state(action)\n",
        "  print('State: ','Bright' if state==1 else 'Dark')\n",
        "  reward=get_reward(state)\n",
        "  print('Reward: ',reward)\n",
        "\n",
        "print('\\n Simulation Complete -Light Control Done')\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AW96S-xjCoHA",
        "outputId": "92475506-250b-4932-c34b-c241d74ed3a0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Room State : 0=Dark , 1=Bright: \t1\n",
            "Action:  0\n",
            "State:  Dark\n",
            "Reward:  0\n",
            "Action:  1\n",
            "State:  Bright\n",
            "Reward:  10\n",
            "Action:  0\n",
            "State:  Dark\n",
            "Reward:  0\n",
            "Action:  1\n",
            "State:  Bright\n",
            "Reward:  10\n",
            "Action:  0\n",
            "State:  Dark\n",
            "Reward:  0\n",
            "Action:  1\n",
            "State:  Bright\n",
            "Reward:  10\n",
            "Action:  0\n",
            "State:  Dark\n",
            "Reward:  0\n",
            "Action:  1\n",
            "State:  Bright\n",
            "Reward:  10\n",
            "Action:  0\n",
            "State:  Dark\n",
            "Reward:  0\n",
            "Action:  1\n",
            "State:  Bright\n",
            "Reward:  10\n",
            "\n",
            " Simulation Complete -Light Control Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Complete Example Water Tank using Reinforcement Learning**"
      ],
      "metadata": {
        "id": "gEW2MnShMykQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "states=np.arange(0,101,10) # 0 to 100\n",
        "actions=[0,1] # 0= Pump Off [Stop] 1=Pump On [Start] on [Fill]"
      ],
      "metadata": {
        "id": "LQ2gBYyMMxT8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('actions: ',actions)\n",
        "print('states: ',states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKB7lIzCNrC4",
        "outputId": "19556c00-aca7-4777-b123-e9eb090000c9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actions:  [0, 1]\n",
            "states:  [  0  10  20  30  40  50  60  70  80  90 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q=np.zeros(((len(states),len(actions))))\n",
        "alpha=0.1\n",
        "gamma=0.9\n",
        "epsilon=0.2\n",
        "episodes=300\n",
        "print('Q-Table: ',Q)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pl6Ms9x6ObyC",
        "outputId": "3ed5b533-9cb6-4381-a33e-00935b01a943"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-Table:  [[0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Q-Table Sahpe: ',Q.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-M6ZYgDO3vS",
        "outputId": "436ede22-e2f1-408d-8016-ad97f2621745"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-Table Sahpe:  (11, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reward(level,action):\n",
        "  reward=0\n",
        "  if 40<=level<=70:\n",
        "    reward+=10\n",
        "  else:\n",
        "    reward-=10\n",
        "  if action==1 and level>=90:\n",
        "    reward-=10\n",
        "  if action==0 and level<=10:\n",
        "    reward-=10\n",
        "  return reward\n"
      ],
      "metadata": {
        "id": "LYkfe6LvPu3G"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Reward Example: \\t',get_reward(60,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jORwMhK_QjCV",
        "outputId": "9facdcfb-7e6f-4961-98c6-2ba2bab9e0c7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward Example: \t 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def next_level(level,action):\n",
        "  if(action==1):\n",
        "   level+=random.choice([5,10,15])\n",
        "  else:\n",
        "    level-=random.choice([5,10,15])\n",
        "  return int(np.clip(level,0,100))\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "pKAc88lyRw-J"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "for episode in range(episodes):\n",
        "  level=random.choice(states)\n",
        "  for _ in range(15):\n",
        "    if random.uniform(0,1)<epsilon:\n",
        "      action=random.choice(actions)\n",
        "    else:\n",
        "      action=actions[np.argmax(Q[level//10])]\n",
        "      next_state=next_level(level,action)\n",
        "      reward=get_reward(next_state,action)\n",
        "      a=actions.index(action)\n",
        "      best_next=np.argmax(Q[next_state//10])\n",
        "      Q[level//10,a]=Q[level//10,a]+alpha*(reward+gamma*best_next-Q[level//10,a])\n",
        "print('Training Complete')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65YfIvMwS-h1",
        "outputId": "8d47bbdc-7485-4e09-c486-dafa901050df"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  level=int(input('Enter Level: '))\n",
        "  if level<0 or level>100:\n",
        "    raise ValueError('Level must be between 0 and 100')\n",
        "except ValueError as ve:\n",
        "  print(ve)\n",
        "  level=50\n",
        "  print('Default level set to 50%')\n",
        "except Exception as ex:\n",
        "  print('Error!!',ex)\n",
        "\n",
        "for step in range(10):\n",
        "  action=actions[np.argmax(Q[level//10])]\n",
        "  print('Action: ',action)\n",
        "  level=next_level(level,action)\n",
        "  print('Level: ',level)\n",
        "  print('State: ','Fill' if level==1 else 'Stop')\n",
        "  reward=get_reward(level,action)\n",
        "  print('Reward: ',reward)\n",
        "\n",
        "print('\\n Simulation Complete -Water Tank Control Done')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhCkZpwxWtnS",
        "outputId": "290ffee2-f6f7-4ea3-dd13-1def4cb88393"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Level: 70\n",
            "Action:  0\n",
            "Level:  60\n",
            "State:  Stop\n",
            "Reward:  10\n",
            "Action:  0\n",
            "Level:  55\n",
            "State:  Stop\n",
            "Reward:  10\n",
            "Action:  1\n",
            "Level:  65\n",
            "State:  Stop\n",
            "Reward:  10\n",
            "Action:  0\n",
            "Level:  55\n",
            "State:  Stop\n",
            "Reward:  10\n",
            "Action:  1\n",
            "Level:  70\n",
            "State:  Stop\n",
            "Reward:  10\n",
            "Action:  0\n",
            "Level:  65\n",
            "State:  Stop\n",
            "Reward:  10\n",
            "Action:  0\n",
            "Level:  50\n",
            "State:  Stop\n",
            "Reward:  10\n",
            "Action:  1\n",
            "Level:  55\n",
            "State:  Stop\n",
            "Reward:  10\n",
            "Action:  1\n",
            "Level:  70\n",
            "State:  Stop\n",
            "Reward:  10\n",
            "Action:  0\n",
            "Level:  65\n",
            "State:  Stop\n",
            "Reward:  10\n",
            "\n",
            " Simulation Complete -Water Tank Control Done\n"
          ]
        }
      ]
    }
  ]
}